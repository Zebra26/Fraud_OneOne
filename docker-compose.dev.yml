services:
  backend:
    build:
      context: .
      dockerfile: backend/Dockerfile
    environment:
      APP_ENV: development
      MONGO_URI: mongodb://mongo:27017/fraud_db
      MONGO_DB: fraud_db
      MONGO_SSL: "false"
      # Updated to 6-node Redis Cluster (3 masters + 3 replicas)
      REDIS_CLUSTER_NODES: "redis-node-0:6379,redis-node-1:6379,redis-node-2:6379,redis-node-3:6379,redis-node-4:6379,redis-node-5:6379"
      REDIS_USE_SSL: "false"
      FEATURE_STORE_URI: redis://redis-node-0:6379
      REDIS_URL: redis://redis-node-0:6379/0
      JWT_SECRET_KEY: dGVzdC1zZWNyZXQ=
      API_HMAC_KEY: aG1hYy1zZWNyZXQ=
      RETRY_ATTEMPTS: "0"
    ports:
      - "8000:8000"
    depends_on:
      - mongo
      - redis-cluster-init
    networks:
      - default
      - redis-internal

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    environment:
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_NODE_ID: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:29093
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,EXTERNAL://0.0.0.0:9094,CONTROLLER://0.0.0.0:29093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,EXTERNAL://localhost:9094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      CLUSTER_ID: Nji2JY9pRdy2JqkLx8aYaw
      KAFKA_LOG_DIRS: /tmp/kraft-combined-logs
    ports:
      - "9094:9092"
    hostname: kafka

  mongo:
    image: mongo:6
    ports:
      - "27017:27017"
    volumes:
      - mongo_data:/data/db

  # Redis Cluster: 6 nodes (3 masters + 3 replicas)
  redis-node-0:
    image: redis:7.2-alpine
    command: >-
      redis-server --bind 0.0.0.0 --port 6379 --cluster-enabled yes
      --cluster-announce-ip redis-node-0 --cluster-announce-port 6379
      --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
    networks:
      - redis-internal

  redis-node-1:
    image: redis:7.2-alpine
    command: >-
      redis-server --bind 0.0.0.0 --port 6379 --cluster-enabled yes
      --cluster-announce-ip redis-node-1 --cluster-announce-port 6379
      --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
    networks:
      - redis-internal

  redis-node-2:
    image: redis:7.2-alpine
    command: >-
      redis-server --bind 0.0.0.0 --port 6379 --cluster-enabled yes
      --cluster-announce-ip redis-node-2 --cluster-announce-port 6379
      --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
    networks:
      - redis-internal

  redis-node-3:
    image: redis:7.2-alpine
    command: >-
      redis-server --bind 0.0.0.0 --port 6379 --cluster-enabled yes
      --cluster-announce-ip redis-node-3 --cluster-announce-port 6379
      --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
    networks:
      - redis-internal

  redis-node-4:
    image: redis:7.2-alpine
    command: >-
      redis-server --bind 0.0.0.0 --port 6379 --cluster-enabled yes
      --cluster-announce-ip redis-node-4 --cluster-announce-port 6379
      --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
    networks:
      - redis-internal

  redis-node-5:
    image: redis:7.2-alpine
    command: >-
      redis-server --bind 0.0.0.0 --port 6379 --cluster-enabled yes
      --cluster-announce-ip redis-node-5 --cluster-announce-port 6379
      --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
    networks:
      - redis-internal

  # One-off job to bootstrap the cluster (3 masters + 3 replicas)
  redis-cluster-init:
    image: redis:7.2-alpine
    depends_on:
      - redis-node-0
      - redis-node-1
      - redis-node-2
      - redis-node-3
      - redis-node-4
      - redis-node-5
    entrypoint: ["sh", "-lc"]
    command: >-
      'sleep 3 &&
      echo yes | redis-cli -a ${REDIS_PASSWORD} --cluster create
      redis-node-0:6379 redis-node-1:6379 redis-node-2:6379 redis-node-3:6379 redis-node-4:6379 redis-node-5:6379
      --cluster-replicas 1'
    networks:
      - redis-internal

  redisinsight:
    image: redislabs/redisinsight:latest
    depends_on:
      - redis-node-0
    ports:
      - "8001:5540"
    environment:
      - REDISINSIGHT_ACCEPT_LICENSE=yes

  ml-inference:
    image: fraud-ml-inference:dev
    build:
      context: .
      dockerfile: services/ml-inference/Dockerfile
    env_file:
      - .env
    environment:
      - APP_ENV=development
      - REDIS_CLUSTER_NODES=redis-node-0:6379,redis-node-1:6379,redis-node-2:6379,redis-node-3:6379,redis-node-4:6379,redis-node-5:6379
      
      - FEATURE_STORE_URI=redis://redis-node-0:6379
      - REDIS_USE_SSL=false
      - ENABLE_JWT_AUTH=true
      - ENABLE_HMAC_SIGNING=true
      - ENABLE_MTLS=false
      - ENABLE_TLS=false
      - JWT_SECRET_KEY=dGVzdC1zZWNyZXQ=
      - API_HMAC_KEY=aG1hYy1zZWNyZXQ=
    depends_on:
      - kafka
      - redis-cluster-init
      - mongo
    networks:
      - redis-internal
    volumes:
      - models_data:/app/models
      - ./backend/tls:/app/tls:ro
      - ./security/certs:/app/security/certs:ro
    labels:
      service: ml-inference

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    depends_on:
      - kafka
    ports:
      - "8080:8080"
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092
      - KAFKA_CLUSTERS_0_PROPERTIES_SECURITY_PROTOCOL=PLAINTEXT

  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
    depends_on:
      - backend
      - ml-inference

  grafana:
    image: grafana/grafana:10.4.3
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
    depends_on:
      - prometheus

  feature-engineering:
    build:
      context: ./services/spark
    depends_on:
      - kafka
    volumes:
      - spark-checkpoints:/opt/checkpoints

  trainer:
    image: fraud-trainer:dev
    build:
      context: ./services/trainer
      dockerfile: Dockerfile
    env_file:
      - .env
    environment:
      MODEL_DIR: /workspace/models
      MODEL_PATH: /workspace/models/ensemble_detector.joblib
      OPTIMAL_THRESHOLD_PATH: /workspace/models/optimal_threshold.txt
      MLFLOW_TRACKING_URI: file:/workspace/mlruns
      MLFLOW_EXPERIMENT_NAME: fraud-detection
      APP_ENV: development
      REDIS_CLUSTER_NODES: redis-node-0:6379,redis-node-1:6379,redis-node-2:6379,redis-node-3:6379,redis-node-4:6379,redis-node-5:6379
      
      FEATURE_STORE_URI: redis://redis-node-0:6379
      REDIS_USE_SSL: "false"
    volumes:
      - models_data:/workspace/models
      - ./mlruns:/workspace/mlruns
    depends_on:
      - mongo
      - redis-node-0 
      - kafka
    command: ["python", "train_pipeline.py"]

  deferred-worker:
    build:
      context: .
      dockerfile: services/deferred-worker/Dockerfile
    env_file:
      - .env
    environment:
      KAFKA_BROKERS: kafka:9092
      DEFERRED_TOPIC: ${DEFERRED_TOPIC:-predictions.deferred}
      KAFKA_TOPIC_PREDICTIONS: ${KAFKA_TOPIC_PREDICTIONS:-predictions}
      INFERENCE_URL: http://ml-inference:8080
      OFFLINE_WRITE: "true"
      MONGO_URI: mongodb://mongo:27017/fraud_db
      MONGO_DB: fraud_db
      REDIS_CLUSTER_NODES: redis-node-0:6379,redis-node-1:6379,redis-node-2:6379,redis-node-3:6379,redis-node-4:6379,redis-node-5:6379
      
      REDIS_USE_SSL: "false"
    depends_on:
      - kafka
      - ml-inference

  mlflow:
    image: ghcr.io/mlflow/mlflow:${MLFLOW_TAG:-latest}
    ports:
      - "5000:5000"
    command:
      - mlflow
      - ui
      - --host
      - 0.0.0.0
      - --port
      - "5000"
      - --backend-store-uri
      - sqlite:///mlruns/mlflow.db
      - --default-artifact-root
      - file:/mlruns
    volumes:
      - ./mlruns:/mlruns

volumes:
  mongo_data:
  spark-checkpoints:
  models_data:
  grafana_data:

networks:
  redis-internal:
    driver: bridge
    internal: true
